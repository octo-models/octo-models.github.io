<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="icon" type="image/png" href="/octo.png">

	<meta name="twitter:card" content="summary_large_image">
	<meta name="twitter:title" content="Octo: An Open-Source Generalist Robot Policy">
	<meta name="twitter:image" content="https://octo-models.github.io/card.jpg">

	<title>üêô Octo: An Open-Source Generalist Robot Policy</title>
	
		<link href="./_app/immutable/assets/0.a87d46dd.css" rel="stylesheet">
		<link href="./_app/immutable/assets/2.ccce21b9.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.77bd5a47.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.df819399.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/singletons.6dbeef66.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/paths.3116f1c1.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.7f8e8436.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.8f68d1ce.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.6e671413.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.1c1b6865.js">
</head>

<body data-sveltekit-preload-data="hover">
	<div style="display: contents">   <div class="w-full h-screen mb-0 flex flex-col items-center justify-center bg-gradient-to-b from-amber-500 to-amber-100 transition-all ease-in-out duration-1000 overflow-hidden relative svelte-2cm2hv"><div class="mx-4 md:mx-16 flex flex-col justify-center pb-32"><h1 class="leading-tight transition-all duration-1000 font-light svelte-2cm2hv"><span class="font-bold"><img src="/octo.png" alt="octo" class="h-[1em] inline align-[-0.1em]">‚ÄàOcto:</span> An Open-Source Generalist Robot Policy</h1></div> <div class="h-32 w-full absolute bottom-0" data-svelte-h="svelte-rtr8ti"><svg class="w-full h-full" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax svelte-2cm2hv"><use xlink:href="#gentle-wave" x="48" y="0" fill="rgba(107, 124, 250, 0.7" class="svelte-2cm2hv"></use><use xlink:href="#gentle-wave" x="48" y="3" fill="rgba(50, 82, 227, 0.5)" class="svelte-2cm2hv"></use><use xlink:href="#gentle-wave" x="48" y="5" fill="rgba(107, 124, 250, 0.3)" class="svelte-2cm2hv"></use><use xlink:href="#gentle-wave" x="48" y="7" fill="rgba(30, 74, 200, 0.8)" class="svelte-2cm2hv"></use></g></svg></div></div>   <div class="max-w-4xl w-full px-2 pt-4 flex flex-col items-center mx-auto" data-svelte-h="svelte-1ou0qde"> <div class="flex flex-col items-center text-xl"><span class="font-bold">Octo Model Team</span> <div class="flex justify-center flex-wrap mt-2 underline decoration-dotted decoration-blue-500 underline-offset-2"><span class="px-2">Dibya Ghosh*<sup>,1</sup></span> <span class="px-2">Homer Walke*<sup>,1</sup></span> <span class="px-2">Karl Pertsch*<sup>,1,2</sup></span> <span class="px-2">Kevin Black*<sup>,1</sup></span> <span class="px-2">Oier Mees*<sup>,1</sup></span></div> <div class="flex justify-center flex-wrap mt-2 underline decoration-dotted decoration-amber-500 underline-offset-2"><span class="px-2">Sudeep Dasari<sup>3</sup></span> <span class="px-2">Joey Hejna<sup>2</sup></span> <span class="px-2">Tobias Kreiman<sup>1</sup></span> <span class="px-2">Charles Xu<sup>1</sup></span> <span class="px-2">Jianlan Luo<sup>1</sup></span> <span class="px-2">You Liang Tan<sup>1</sup></span></div> <div class="flex justify-center flex-wrap mt-2 underline decoration-dotted decoration-green-500 underline-offset-2"><span class="px-2">Pannag Sanketi<sup>4</sup></span> <span class="px-2">Quan Vuong<sup>4</sup></span> <span class="px-2">Ted Xiao<sup>4</sup></span> <span class="px-2">Dorsa Sadigh<sup>2</sup></span> <span class="px-2">Chelsea Finn<sup>2</sup></span> <span class="px-2">Sergey Levine<sup>1</sup></span></div> <div class="flex justify-center mt-4 mx-2 text-center">*denotes equal contribution, listed in alphabetical order</div> <div class="flex justify-center flex-wrap mt-4"><span class="px-4">1. UC Berkeley</span> <span class="px-4">2. Stanford University</span> <span class="px-4">3. Carnegie Mellon University</span> <span class="px-4">4. Google DeepMind</span></div></div>  <div class="flex w-full justify-between text-center pt-4 text-lg pb-4 mx-auto px-4"><div class="flex flex-col justify-end hover:bg-sky-200 rounded-md w-32"><a href="https://arxiv.org/pdf/2405.12213" class="hover:underline text-black p-4 flex flex-col items-center"><img src="/documents.svg" alt="documents" class="w-16">
				Report</a></div> <div class="flex flex-col justify-end hover:bg-sky-200 rounded-md w-32"><a href="https://github.com/octo-models/octo" class="hover:underline text-black p-4 flex flex-col items-center"><img src="/github-mark.svg" alt="code" class="w-16">
				Code</a></div> <div class="flex flex-col justify-end hover:bg-sky-200 rounded-md w-32"><a href="https://colab.research.google.com/drive/1z0vELj_lX9OWeoMG_WvXnQs43aPOEAhz?usp=sharing" class="hover:underline text-black p-4 flex flex-col items-center"><img src="/colab2.svg" alt="colab" class="w-20">
				Colab</a></div> <div class="flex flex-col justify-end hover:bg-sky-200 rounded-md w-32"><a href="https://huggingface.co/rail-berkeley" class="hover:underline text-black p-4 flex flex-col items-center"><img src="/weights.svg" alt="weights" class="w-16">
				Weights</a></div></div></div>  <div class="w-full bg-slate-100 px-2 md:px-16 py-8"><div class="w-full flex justify-center" id="container"> <div class="splide"><div class="splide__track"><ul class="splide__list"><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_ours_ur5_tiger.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_cmu.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_iliad.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_ours_ur5_cloth.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_fmb.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_bridge.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_rpt.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_aloha.jpg"></div> </div> </li><li class="splide__slide"><div class="px-2"><div class="rounded-lg overflow-hidden flex justify-center w-full"><img class="w-full" autoplay src="/videos/out_google.jpg"></div> </div> </li></ul></div></div> </div></div>  <div class="max-w-6xl w-full px-2 pt-4 mx-auto"> <p class="mt-8 text-l">We introduce Octo‚Äà<img src="/octo.png" alt="octo" class="h-[1em] inline align-[-0.1em]">, our ongoing effort for building open-source, widely applicable generalist
		policies for robotic manipulation. The Octo model is a transformer-based diffusion policy,
		pretrained on 800k robot episodes from the
		<a href="https://robotics-transformer-x.github.io/" data-svelte-h="svelte-14855xq">Open X-Embodiment dataset</a>. It supports
		flexible task and observation definitions and can be quickly finetuned to new observation and
		action spaces. We are introducing two initial versions of Octo, Octo-Small (27M parameters) and
		Octo-Base (93M parameters).</p> <img src="/teaser.jpg" alt="teaser" class="w-full mt-16 px-2 md:px-16">  <h2 class="text-4xl mt-16" data-svelte-h="svelte-7bnceo">The Model</h2> <p class="mt-8" data-svelte-h="svelte-14jxxfh">The design of the Octo model emphasizes flexibility and scale: the model is designed to support
		a variety of commonly used robots, sensor configurations, and actions, while providing a generic
		and scalable recipe that can be trained on large amounts of data. Octo supports both natural
		language instructions and goal images, observation histories, and multi-modal action
		distributions via diffusion decoding. Furthermore, we designed Octo specifically to support
		efficient finetuning to new robot setups, including robots with different actions and different
		combinations of cameras and proprioceptive information. This design was selected specifically to
		make Octo a flexible and broadly applicable generalist robotic policy that can be utilized for a
		variety of downstream robotics applications and research projects.

		<img src="/architecture.jpg" alt="model" class="w-full mt-16 px-2 md:px-16"></p>  <h2 class="text-4xl mt-16" data-svelte-h="svelte-j9rfip">The Data</h2> <p class="mt-8" data-svelte-h="svelte-9qqk1n">We train Octo on a mixture of 25 datasets from the Open X-Embodiment Dataset, a diverse
		collection of robot learning datasets. Our training mixture includes data from a variety of
		robot embodiments, scenes, and tasks. These datasets are heterogeneous not just in terms of the
		robot type, but also in the sensors (e.g., including or not including wrist cameras) and labels
		(e.g., including or not including language instructions).
		<img src="/sampling_weights.jpg" alt="model" class="w-3/4 px-2 md:w-1/2 mt-10 mx-auto"></p>  <h2 class="text-4xl mt-16" data-svelte-h="svelte-vfli5r">The Results</h2> <p class="mt-8" data-svelte-h="svelte-1snp58p">We evaluate Octo on 9 real robot setups across 4 institutions. Our evaluations capture diverse
		object interactions (e.g., &quot;WidowX BridgeV2&quot;), long task horizons (e.g., &quot;Stanford Coffee&quot;) and
		precise manipulation (e.g., &quot;Berkeley Peg Insert&quot;). We evaluate Octo&#39;s capabilities to control
		robots in environments from the pretraining data out-of-the-box and to efficiently finetune to
		new tasks and environments with small target domain datasets. We also test finetuning with new
		observations (force-torque inputs for &quot;Berkeley Peg Insert&quot;) and action spaces (joint position
		control in &quot;Berkeley Pick-Up&quot;).
		<img src="/exp_setups.jpg" alt="model" class="w-full mt-16 px-2 md:px-8 mx-auto"></p> <div class="flex flex-wrap gap-y-4 justify-center mt-16"><table class="mr-2 md:mr-4 border-collapse text-center text-xs"><thead data-svelte-h="svelte-b5so5l"><tr><th colspan="4" class="text-lg svelte-ii6qa2">Zero-shot</th></tr> <tr class="border-b border-t-2 border-black"><th class="svelte-ii6qa2"></th> <th class="svelte-ii6qa2">WidowX</th> <th class="svelte-ii6qa2">UR5</th> <th class="svelte-ii6qa2">RT-1 Robot</th></tr></thead> <tbody><tr class="md:border-b-8 md:border-b-transparent svelte-ii6qa2" data-svelte-h="svelte-1tss8wq"><td class="svelte-ii6qa2">RT-1-X</td> <td class="svelte-ii6qa2">0.20</td> <td class="svelte-ii6qa2">0.35</td> <td class="svelte-ii6qa2">0.60</td></tr> <tr class="md:border-b-8 md:border-b-transparent svelte-ii6qa2" data-svelte-h="svelte-13hmizx"><td class="svelte-ii6qa2">RT-2-X</td> <td class="font-bold svelte-ii6qa2">0.50</td> <td class="svelte-ii6qa2">‚Äî</td> <td class="font-bold svelte-ii6qa2">0.85</td></tr> <tr class="border-b-2 border-black font-bold svelte-ii6qa2"><td class="svelte-ii6qa2">Octo‚Äà<img src="/octo.png" alt="octo" class="h-[1em] inline align-[-0.1em]"></td> <td class="svelte-ii6qa2" data-svelte-h="svelte-1jskovd">0.50</td> <td class="svelte-ii6qa2" data-svelte-h="svelte-g0d817">0.70</td> <td class="font-normal svelte-ii6qa2" data-svelte-h="svelte-15jphg4">0.80</td></tr></tbody></table> <table class="ml-2 md:ml-4 border-collapse text-center md:text-xs text-[0.5rem]"><thead data-svelte-h="svelte-12sp3gu"><tr><th colspan="8" class="text-lg svelte-ii6qa2">Finetuning</th></tr> <tr class="border-b border-t-2 border-black"><th class="svelte-ii6qa2"></th> <th class="svelte-ii6qa2">CMU Baking</th> <th class="svelte-ii6qa2">Stanford Coffee</th> <th class="svelte-ii6qa2">Berkeley Peg Insert<sup>*</sup></th> <th class="svelte-ii6qa2">Berkeley Pick-Up<sup>‚Ä†</sup></th> <th class="svelte-ii6qa2">Berkeley Bimanual<sup>‚Ä†</sup></th> <th class="svelte-ii6qa2">Berkeley Coke</th> <th class="svelte-ii6qa2">Average</th></tr></thead> <tbody><tr class="md:border-b-8 md:border-b-transparent svelte-ii6qa2" data-svelte-h="svelte-9i74ow"><td class="svelte-ii6qa2">From Scratch</td> <td class="svelte-ii6qa2">0.25</td> <td class="svelte-ii6qa2">0.45</td> <td class="svelte-ii6qa2">0.10</td> <td class="svelte-ii6qa2">0.00</td> <td class="svelte-ii6qa2">0.20</td> <td class="svelte-ii6qa2">0.20</td> <td class="svelte-ii6qa2">0.20</td></tr> <tr class="md:border-b-8 md:border-b-transparent svelte-ii6qa2" data-svelte-h="svelte-1y9h0n7"><td class="svelte-ii6qa2"><a href="https://eai-vc.github.io/">VC-1</a></td> <td class="svelte-ii6qa2">0.30</td> <td class="svelte-ii6qa2">0.00</td> <td class="svelte-ii6qa2">0.05</td> <td class="svelte-ii6qa2">0.00</td> <td class="svelte-ii6qa2">0.50</td> <td class="svelte-ii6qa2">0.10</td> <td class="svelte-ii6qa2">0.15</td></tr> <tr class="border-b-2 border-black font-bold svelte-ii6qa2"><td class="svelte-ii6qa2">Octo‚Äà<img src="/octo.png" alt="octo" class="h-[1em] inline align-[-0.1em]"></td> <td class="svelte-ii6qa2" data-svelte-h="svelte-1jskovd">0.50</td> <td class="svelte-ii6qa2" data-svelte-h="svelte-uuwxug">0.75</td> <td class="svelte-ii6qa2" data-svelte-h="svelte-g0d817">0.70</td> <td class="svelte-ii6qa2" data-svelte-h="svelte-trvq3u">0.60</td> <td class="svelte-ii6qa2" data-svelte-h="svelte-1p0sb18">0.80</td> <td class="svelte-ii6qa2" data-svelte-h="svelte-1pgmcwh">1.00</td> <td class="svelte-ii6qa2" data-svelte-h="svelte-dg0hmd">0.72</td></tr></tbody></table></div> <div class="mt-2 flex justify-center text-[0.5rem] md:text-sm" data-svelte-h="svelte-1o1eylg"><div class="px-4"><sup>*</sup>New observation input (force-torque proprioception)</div> <div class="px-4"><sup>‚Ä†</sup>New action space (joint position control)</div></div> <p class="mt-8" data-svelte-h="svelte-1te8rbi">Out-of-the-box, Octo can control multiple robots in environments from the pretraining data. When
		using natural language to specify tasks, it outperforms <a href="https://robotics-transformer-x.github.io/">RT-1-X</a>: the current best, openly available generalist robotic policy. It performs similarly to
		<a href="https://robotics-transformer-x.github.io/">RT-2-X</a>, a 55-billion parameter model.
		Additionally, while RT-1-X and RT-2-X only support language conditioning, Octo also supports
		goal image conditioning. On the WidowX tasks, we found that Octo achieved even better
		performance with goal image conditioning ‚Äî 25% higher on average ‚Äî likely because
		goal images provide more information about how to achieve the task.</p> <p class="mt-4" data-svelte-h="svelte-1piupnw">We also find that finetuning Octo leads to better policies than starting from scratch or with
		the pretrained <a href="https://eai-vc.github.io">VC-1</a> weights. On average across the six evaluation 
		setups, Octo outperforms the next best baseline by 52%. Each task uses ~100 target
		demonstrations. Importantly, we use
		<a href="https://github.com/octo-models/octo/blob/main/scripts/configs/finetune_config.py">the same finetuning recipe</a> for all evaluation tasks, making this a good default configuration for Octo finetuning. The results 
		also underline Octo‚Äôs ability to accommodate new observations (force-torque inputs for ‚ÄúBerkeley Insertion‚Äù),
		action spaces (joint position control for ‚ÄúBerkeley Pick-Up‚Äù) and new robot embodiments (‚ÄúBerkeley Bi-Manual‚Äù 
		and ‚ÄúBerkeley Coke‚Äù). This makes Octo applicable to a wide range of single and dual arm robotic manipulation 
		problems that go beyond a single camera input and end-effector position control.</p> <div class="mt-8 md:ml-4 ml-1 text-left"></div>  <h2 class="text-4xl mt-16" data-svelte-h="svelte-1onhk75">Citation</h2> <p class="mt-8" data-svelte-h="svelte-1bcmm9r">Please use the following BibTeX entry to cite this work:</p> <pre class="mt-4 overflow-x-scroll bg-slate-100 p-8">@inproceedings{octo_2023,
    title={Octo: An Open-Source Generalist Robot Policy},
    author = {{Octo Model Team} and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Charles Xu and Jianlan Luo and Tobias Kreiman and {You Liang} Tan and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine},
    booktitle = {Proceedings of Robotics: Science and Systems},
    address  = {Delft, Netherlands},
    year = {2024},
}</pre> </div> 
			
			<script>
				{
					__sveltekit_1e0osr9 = {
						base: new URL(".", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./_app/immutable/entry/start.77bd5a47.js"),
						import("./_app/immutable/entry/app.7f8e8436.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>